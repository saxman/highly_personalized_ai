{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92a763-e30d-4bae-8a79-9cb0d8a58f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Mistral-style models\n",
    "# model_id = \"GritLM/GritLM-7B\"\n",
    "# model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# model_id = \"google/gemma-1.1-7b-it\"\n",
    "\n",
    "## Llama-style models\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"nvidia/Llama3-ChatQA-1.5-8B\"\n",
    "# model_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "model_id = \"models/meta-llama__Meta-Llama-3-70B-Instruct\"\n",
    "\n",
    "model_kwargs = {\n",
    "    \"low_cpu_mem_usage\": True,\n",
    "    \"device_map\": \"sequential\"\n",
    "}\n",
    "\n",
    "generate_kwargs = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e20b5c-3ff7-49ce-9db5-8c4fe13f487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TextStreamer\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"conversational\",\n",
    "    model=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    "    tokenizer=tokenizer,\n",
    "    streamer=streamer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d92f5e-942f-4d9f-a0c8-75c5883ee82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "utils.print_model_info(pipe.model)\n",
    "utils.print_device_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7909c87-9ab9-405f-afce-d599071d71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_role = \"system\"\n",
    "# system_role = \"user\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are the user's friend and you care about their well being.\n",
    "You will converse with the user and attempt to get to know them better.\n",
    "You will only ask one question in each of your responses.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": system_role,\n",
    "        \"content\": system_prompt,\n",
    "    }\n",
    "]\n",
    "\n",
    "_ = pipe(messages, kwargs=generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e67297-ad5e-44b9-9b3a-62a786ce195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Everything is good! I'm excited to be developing AI technology lately.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "_ = pipe(messages, kwargs=generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868079ec-4a61-4df7-ae2c-12346e9de4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I want to develop advanced tools for personalizing AI interactions.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "_ = pipe(messages, kwargs=generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa0b15-eec6-4a5c-bdd5-8730a8cc46c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
